{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install plugnplai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plugnplai as pl\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our chosen Plugins: ['https://showme.redstarplugin.com']\n"
     ]
    }
   ],
   "source": [
    "# Get working plugins - only tested plugins (in progress)\n",
    "urlsTravel = pl.get_plugins()\n",
    "\n",
    "# Lets pick Trip, Klarna and Speak\n",
    "urls = [plugin for plugin in urlsTravel if any(word in plugin for word in ('Diagram It', 'showme'))]\n",
    "\n",
    "print(f'Our chosen Plugins: {urls}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plugnplai import Plugins\n",
    "\n",
    "plugins = Plugins.install_and_activate(urls)\n",
    "chat = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "@plugins.apply_plugins\n",
    "def call_llm(user_message):\n",
    "  messages = [\n",
    "    SystemMessage(content=\"\"),\n",
    "    HumanMessage(content=user_message)\n",
    "  ]\n",
    "\n",
    "  res = chat(messages)\n",
    "\n",
    "  llm_first_response = res.content\n",
    "\n",
    "  return llm_first_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using show_me_diagrams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2fb8e1aa721b2e220fb448dacd8a7c6b in your message.).\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here is a diagram that shows the Android Application lifecycle:\n",
       "\n",
       "```mermaid\n",
       "sequenceDiagram\n",
       "    participant User\n",
       "    participant Activity\n",
       "    participant Service\n",
       "    participant Broadcast Receiver\n",
       "    participant Content Provider\n",
       "    User->>Activity: Starts an Activity\n",
       "    Activity->>Service: Starts a Service\n",
       "    Service->>Broadcast Receiver: Sends a Broadcast\n",
       "    Broadcast Receiver->>Content Provider: Accesses Content Provider\n",
       "    Content Provider->>User: Returns data\n",
       "```\n",
       "\n",
       "In the Android Application lifecycle, a user starts an Activity, which can then start a Service. The Service can send a Broadcast to a Broadcast Receiver, which can access a Content Provider to retrieve data. The Content Provider then returns the data to the user."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Message that triggers the use of plugin 1\n",
    "response = call_llm(\"show me  Android Application lifecycle\")\n",
    "# Display in markdown format\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
